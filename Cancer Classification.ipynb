{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2777,
     "status": "ok",
     "timestamp": 1669204629610,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "JPy9tnwrhTiZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 2150,
     "status": "ok",
     "timestamp": 1669204707162,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "Wat00Qa8iQO9",
    "outputId": "76d4d79e-9327-4bc2-bee2-e344b3fe43b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cancer_classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669204711462,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "hhYWDP8hi1nj",
    "outputId": "38fb7498-9a4e-4f6f-9982-67740c781479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669204713381,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "IZjz0d9vkaIM",
    "outputId": "2661ac6d-34c9-483f-a216-680d0414947b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1669204713866,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "yK3-Vs2ykf-Z",
    "outputId": "2ed22144-8917-4887-c523-2accae749769"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"target\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669204713867,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "5Rl1E9LClAxe",
    "outputId": "e0fc222c-8ad3-4a7b-a5bb-ecf113b5da5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669204714312,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "KV2owyFDldaI"
   },
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669204714953,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "JPEw10TGm0ki",
    "outputId": "7c7f8b30-05e4-42f1-8e58-875cbf48a5c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1669204716557,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "cbt0E_3gl9N-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1669204716559,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "VviwKLpsmsli"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtest=sc.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46440,
     "status": "ok",
     "timestamp": 1669204763609,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "woTAHI3BnlRZ",
    "outputId": "481cc140-23db-4954-e447-a951b16ef8f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 2s 29ms/step - loss: 0.6550 - val_loss: 0.5373\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4593 - val_loss: 0.3967\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3425 - val_loss: 0.3151\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2640 - val_loss: 0.2615\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2082 - val_loss: 0.2238\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1703 - val_loss: 0.1961\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1455 - val_loss: 0.1754\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1272 - val_loss: 0.1600\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1144 - val_loss: 0.1477\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1028 - val_loss: 0.1377\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0939 - val_loss: 0.1306\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0868 - val_loss: 0.1257\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0808 - val_loss: 0.1210\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0755 - val_loss: 0.1177\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0711 - val_loss: 0.1154\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0676 - val_loss: 0.1138\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0640 - val_loss: 0.1122\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.1105\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0581 - val_loss: 0.1095\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0555 - val_loss: 0.1089\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0531 - val_loss: 0.1072\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.1077\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0483 - val_loss: 0.1069\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0464 - val_loss: 0.1063\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0445 - val_loss: 0.1070\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.1068\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0403 - val_loss: 0.1075\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.1061\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0372 - val_loss: 0.1056\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0359 - val_loss: 0.1079\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.1069\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.1068\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.1079\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0301 - val_loss: 0.1060\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.1072\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.1071\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.1077\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0256 - val_loss: 0.1073\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.1082\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.1091\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.1101\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.1107\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.1114\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.1108\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.1105\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.1128\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.1138\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.1142\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.1143\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.1149\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.1162\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.1162\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.1172\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.1171\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.1159\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.1174\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.1186\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.1189\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.1194\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.1204\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.1204\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.1223\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.1215\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.1198\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.1215\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.1227\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.1226\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.1235\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.1243\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.1244\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.1262\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.1261\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.1268\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.1279\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.1284\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.1289\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.1298\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.1310\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.1309\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.1310\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.1324\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.1339\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.1342\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.1346\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.1351\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.1359\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.1367\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.1372\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.1372\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.1390\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.1394\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.1395\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.1393\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.1398\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.1403\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.1419\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.1419\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.1432\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.1434\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.1447\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.1455\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.1458\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.1458\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.1474\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.1485\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.1486\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 0.1483\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.1486\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.1498\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.1507\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.1513\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.1516\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1520\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.1527\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.1537\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1546\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.1551\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.1555\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.1567\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.1569\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.1568\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.1579\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.1586\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.1591\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.1597\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.1603\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.1612\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.1619\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.1627\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.1635\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.1640\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.1646\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.1647\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.1653\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1658\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1667\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1686\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1692\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.1696\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.1700\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.1703\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.1709\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.1718\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.1725\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1726\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8159e-04 - val_loss: 0.1733\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6768e-04 - val_loss: 0.1738\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4224e-04 - val_loss: 0.1746\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4793e-04 - val_loss: 0.1751\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.3068e-04 - val_loss: 0.1761\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4843e-04 - val_loss: 0.1764\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0972e-04 - val_loss: 0.1769\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.6939e-04 - val_loss: 0.1775\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4317e-04 - val_loss: 0.1778\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1951e-04 - val_loss: 0.1786\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0646e-04 - val_loss: 0.1795\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9344e-04 - val_loss: 0.1802\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7243e-04 - val_loss: 0.1805\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.6189e-04 - val_loss: 0.1811\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4622e-04 - val_loss: 0.1818\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.3501e-04 - val_loss: 0.1824\n",
      "Epoch 163/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3926e-04 - val_loss: 0.1830\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0880e-04 - val_loss: 0.1836\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.9591e-04 - val_loss: 0.1840\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.9209e-04 - val_loss: 0.1844\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7725e-04 - val_loss: 0.1855\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6085e-04 - val_loss: 0.1859\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.5183e-04 - val_loss: 0.1864\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.4195e-04 - val_loss: 0.1867\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.2551e-04 - val_loss: 0.1873\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2455e-04 - val_loss: 0.1877\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 6.0116e-04 - val_loss: 0.1881\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 5.9708e-04 - val_loss: 0.1890\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.9283e-04 - val_loss: 0.1894\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 5.6663e-04 - val_loss: 0.1897\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 5.5975e-04 - val_loss: 0.1902\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.5080e-04 - val_loss: 0.1907\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 5.5030e-04 - val_loss: 0.1910\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.3512e-04 - val_loss: 0.1917\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.2445e-04 - val_loss: 0.1921\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.2436e-04 - val_loss: 0.1929\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 5.1164e-04 - val_loss: 0.1932\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 4.9932e-04 - val_loss: 0.1937\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9492e-04 - val_loss: 0.1941\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.9021e-04 - val_loss: 0.1948\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.7307e-04 - val_loss: 0.1954\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 4.6761e-04 - val_loss: 0.1959\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.6255e-04 - val_loss: 0.1961\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5400e-04 - val_loss: 0.1971\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4405e-04 - val_loss: 0.1975\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.3704e-04 - val_loss: 0.1978\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2838e-04 - val_loss: 0.1984\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.2978e-04 - val_loss: 0.1990\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2409e-04 - val_loss: 0.1994\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4.1922e-04 - val_loss: 0.1998\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 4.0767e-04 - val_loss: 0.1998\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.0147e-04 - val_loss: 0.2011\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.0006e-04 - val_loss: 0.2016\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0605e-04 - val_loss: 0.2024\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9827e-04 - val_loss: 0.2027\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.8476e-04 - val_loss: 0.2032\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.7198e-04 - val_loss: 0.2040\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6604e-04 - val_loss: 0.2046\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 3.5915e-04 - val_loss: 0.2051\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.5069e-04 - val_loss: 0.2051\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.4550e-04 - val_loss: 0.2059\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.3946e-04 - val_loss: 0.2063\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3300e-04 - val_loss: 0.2067\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3389e-04 - val_loss: 0.2073\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2495e-04 - val_loss: 0.2077\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2023e-04 - val_loss: 0.2080\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1630e-04 - val_loss: 0.2087\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1147e-04 - val_loss: 0.2093\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.0586e-04 - val_loss: 0.2093\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.0216e-04 - val_loss: 0.2099\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9934e-04 - val_loss: 0.2103\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9649e-04 - val_loss: 0.2105\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9010e-04 - val_loss: 0.2111\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.8827e-04 - val_loss: 0.2118\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 2.8530e-04 - val_loss: 0.2125\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.7975e-04 - val_loss: 0.2127\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7529e-04 - val_loss: 0.2131\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7266e-04 - val_loss: 0.2134\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7124e-04 - val_loss: 0.2141\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6774e-04 - val_loss: 0.2143\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 2.7134e-04 - val_loss: 0.2144\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.6380e-04 - val_loss: 0.2147\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.5457e-04 - val_loss: 0.2154\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.5259e-04 - val_loss: 0.2161\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.4982e-04 - val_loss: 0.2166\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.4363e-04 - val_loss: 0.2169\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3914e-04 - val_loss: 0.2177\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 2.4184e-04 - val_loss: 0.2183\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3898e-04 - val_loss: 0.2184\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3335e-04 - val_loss: 0.2187\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.2602e-04 - val_loss: 0.2195\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 2.2316e-04 - val_loss: 0.2199\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1746e-04 - val_loss: 0.2208\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1437e-04 - val_loss: 0.2211\n",
      "Epoch 241/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1206e-04 - val_loss: 0.2215\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1098e-04 - val_loss: 0.2217\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0680e-04 - val_loss: 0.2222\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0434e-04 - val_loss: 0.2225\n",
      "Epoch 245/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0081e-04 - val_loss: 0.2233\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9967e-04 - val_loss: 0.2237\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9702e-04 - val_loss: 0.2240\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9482e-04 - val_loss: 0.2242\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9168e-04 - val_loss: 0.2248\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9064e-04 - val_loss: 0.2251\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.8759e-04 - val_loss: 0.2255\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8553e-04 - val_loss: 0.2264\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8472e-04 - val_loss: 0.2265\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7981e-04 - val_loss: 0.2266\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7904e-04 - val_loss: 0.2273\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7621e-04 - val_loss: 0.2275\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7312e-04 - val_loss: 0.2283\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7337e-04 - val_loss: 0.2287\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6922e-04 - val_loss: 0.2292\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6563e-04 - val_loss: 0.2294\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6545e-04 - val_loss: 0.2301\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.6170e-04 - val_loss: 0.2305\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.5999e-04 - val_loss: 0.2308\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5793e-04 - val_loss: 0.2314\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5755e-04 - val_loss: 0.2321\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5919e-04 - val_loss: 0.2324\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5836e-04 - val_loss: 0.2323\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5400e-04 - val_loss: 0.2326\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4913e-04 - val_loss: 0.2330\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4653e-04 - val_loss: 0.2335\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4621e-04 - val_loss: 0.2343\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4197e-04 - val_loss: 0.2345\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4079e-04 - val_loss: 0.2350\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4024e-04 - val_loss: 0.2352\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3802e-04 - val_loss: 0.2357\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3586e-04 - val_loss: 0.2362\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3598e-04 - val_loss: 0.2365\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3247e-04 - val_loss: 0.2372\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3277e-04 - val_loss: 0.2373\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3052e-04 - val_loss: 0.2379\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2818e-04 - val_loss: 0.2380\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2805e-04 - val_loss: 0.2384\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2578e-04 - val_loss: 0.2387\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2375e-04 - val_loss: 0.2393\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2296e-04 - val_loss: 0.2396\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2128e-04 - val_loss: 0.2399\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2153e-04 - val_loss: 0.2403\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1969e-04 - val_loss: 0.2407\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1750e-04 - val_loss: 0.2408\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1639e-04 - val_loss: 0.2413\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1438e-04 - val_loss: 0.2416\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1314e-04 - val_loss: 0.2419\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1267e-04 - val_loss: 0.2424\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1058e-04 - val_loss: 0.2428\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1037e-04 - val_loss: 0.2430\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0853e-04 - val_loss: 0.2433\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0715e-04 - val_loss: 0.2437\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0725e-04 - val_loss: 0.2442\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0521e-04 - val_loss: 0.2444\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0357e-04 - val_loss: 0.2450\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0197e-04 - val_loss: 0.2453\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0152e-04 - val_loss: 0.2455\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.9766e-05 - val_loss: 0.2458\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.8574e-05 - val_loss: 0.2462\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.7967e-05 - val_loss: 0.2465\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.6565e-05 - val_loss: 0.2473\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.6502e-05 - val_loss: 0.2475\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4920e-05 - val_loss: 0.2482\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.4198e-05 - val_loss: 0.2484\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.2738e-05 - val_loss: 0.2487\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.1570e-05 - val_loss: 0.2490\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.0460e-05 - val_loss: 0.2495\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.0677e-05 - val_loss: 0.2496\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.8869e-05 - val_loss: 0.2496\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.8039e-05 - val_loss: 0.2502\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.7225e-05 - val_loss: 0.2507\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6089e-05 - val_loss: 0.2509\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5906e-05 - val_loss: 0.2514\n",
      "Epoch 319/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 8.4021e-05 - val_loss: 0.2517\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3061e-05 - val_loss: 0.2521\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2854e-05 - val_loss: 0.2523\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2424e-05 - val_loss: 0.2527\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1952e-05 - val_loss: 0.2531\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9734e-05 - val_loss: 0.2533\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.9127e-05 - val_loss: 0.2536\n",
      "Epoch 326/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8622e-05 - val_loss: 0.2540\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7408e-05 - val_loss: 0.2542\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.6775e-05 - val_loss: 0.2546\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.5030e-05 - val_loss: 0.2550\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.4465e-05 - val_loss: 0.2554\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3583e-05 - val_loss: 0.2556\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.2948e-05 - val_loss: 0.2561\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1976e-05 - val_loss: 0.2565\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.2054e-05 - val_loss: 0.2569\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.1772e-05 - val_loss: 0.2572\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.0797e-05 - val_loss: 0.2576\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.9319e-05 - val_loss: 0.2578\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8208e-05 - val_loss: 0.2583\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8572e-05 - val_loss: 0.2587\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7587e-05 - val_loss: 0.2588\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6633e-05 - val_loss: 0.2593\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5622e-05 - val_loss: 0.2596\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 6.5136e-05 - val_loss: 0.2599\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.4269e-05 - val_loss: 0.2602\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.3728e-05 - val_loss: 0.2606\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3129e-05 - val_loss: 0.2611\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.2626e-05 - val_loss: 0.2615\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.2183e-05 - val_loss: 0.2618\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.1235e-05 - val_loss: 0.2625\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.0843e-05 - val_loss: 0.2629\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.9769e-05 - val_loss: 0.2633\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.0054e-05 - val_loss: 0.2635\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.9250e-05 - val_loss: 0.2636\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.8830e-05 - val_loss: 0.2638\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7306e-05 - val_loss: 0.2642\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7740e-05 - val_loss: 0.2647\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6610e-05 - val_loss: 0.2649\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6367e-05 - val_loss: 0.2654\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.5305e-05 - val_loss: 0.2655\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.4783e-05 - val_loss: 0.2660\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.4181e-05 - val_loss: 0.2662\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.3477e-05 - val_loss: 0.2665\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.3110e-05 - val_loss: 0.2670\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.3193e-05 - val_loss: 0.2673\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.1960e-05 - val_loss: 0.2675\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1552e-05 - val_loss: 0.2677\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1827e-05 - val_loss: 0.2682\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.0239e-05 - val_loss: 0.2689\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.0232e-05 - val_loss: 0.2694\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9308e-05 - val_loss: 0.2695\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9358e-05 - val_loss: 0.2698\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 4.8491e-05 - val_loss: 0.2700\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.8006e-05 - val_loss: 0.2704\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.8246e-05 - val_loss: 0.2708\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.7259e-05 - val_loss: 0.2708\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.6840e-05 - val_loss: 0.2714\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.6328e-05 - val_loss: 0.2716\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5553e-05 - val_loss: 0.2719\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5156e-05 - val_loss: 0.2725\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4780e-05 - val_loss: 0.2726\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4190e-05 - val_loss: 0.2730\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4094e-05 - val_loss: 0.2732\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3780e-05 - val_loss: 0.2734\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2945e-05 - val_loss: 0.2737\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.2812e-05 - val_loss: 0.2741\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.2210e-05 - val_loss: 0.2744\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.1941e-05 - val_loss: 0.2747\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1379e-05 - val_loss: 0.2750\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.1249e-05 - val_loss: 0.2755\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.0400e-05 - val_loss: 0.2757\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9995e-05 - val_loss: 0.2760\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9936e-05 - val_loss: 0.2765\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9639e-05 - val_loss: 0.2769\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.9031e-05 - val_loss: 0.2771\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.8786e-05 - val_loss: 0.2773\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.8528e-05 - val_loss: 0.2776\n",
      "Epoch 397/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7854e-05 - val_loss: 0.2778\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7533e-05 - val_loss: 0.2782\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.7331e-05 - val_loss: 0.2787\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7041e-05 - val_loss: 0.2788\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.6435e-05 - val_loss: 0.2795\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6456e-05 - val_loss: 0.2798\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.5641e-05 - val_loss: 0.2799\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.5510e-05 - val_loss: 0.2804\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.5100e-05 - val_loss: 0.2806\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.4743e-05 - val_loss: 0.2809\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.4378e-05 - val_loss: 0.2809\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4157e-05 - val_loss: 0.2815\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.3692e-05 - val_loss: 0.2817\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3790e-05 - val_loss: 0.2819\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3332e-05 - val_loss: 0.2823\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2811e-05 - val_loss: 0.2827\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2552e-05 - val_loss: 0.2832\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.2228e-05 - val_loss: 0.2836\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2051e-05 - val_loss: 0.2838\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1596e-05 - val_loss: 0.2842\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1224e-05 - val_loss: 0.2843\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1248e-05 - val_loss: 0.2848\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.0714e-05 - val_loss: 0.2850\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.0392e-05 - val_loss: 0.2853\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.0253e-05 - val_loss: 0.2854\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.9879e-05 - val_loss: 0.2857\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9832e-05 - val_loss: 0.2859\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.9362e-05 - val_loss: 0.2865\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.9182e-05 - val_loss: 0.2868\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.8803e-05 - val_loss: 0.2872\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.8922e-05 - val_loss: 0.2872\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.8174e-05 - val_loss: 0.2879\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.8737e-05 - val_loss: 0.2880\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8282e-05 - val_loss: 0.2882\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7537e-05 - val_loss: 0.2885\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 2.7236e-05 - val_loss: 0.2890\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.7068e-05 - val_loss: 0.2892\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.7150e-05 - val_loss: 0.2895\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6667e-05 - val_loss: 0.2896\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6150e-05 - val_loss: 0.2901\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6133e-05 - val_loss: 0.2904\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.5691e-05 - val_loss: 0.2907\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5381e-05 - val_loss: 0.2913\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5434e-05 - val_loss: 0.2912\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4978e-05 - val_loss: 0.2914\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4890e-05 - val_loss: 0.2917\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4509e-05 - val_loss: 0.2923\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4443e-05 - val_loss: 0.2925\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4091e-05 - val_loss: 0.2928\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3918e-05 - val_loss: 0.2929\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3649e-05 - val_loss: 0.2934\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3656e-05 - val_loss: 0.2938\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3280e-05 - val_loss: 0.2942\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3064e-05 - val_loss: 0.2945\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3103e-05 - val_loss: 0.2948\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2692e-05 - val_loss: 0.2949\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2481e-05 - val_loss: 0.2951\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2334e-05 - val_loss: 0.2954\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2090e-05 - val_loss: 0.2955\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1875e-05 - val_loss: 0.2959\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.1685e-05 - val_loss: 0.2963\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 2.1418e-05 - val_loss: 0.2965\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.1374e-05 - val_loss: 0.2968\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.1063e-05 - val_loss: 0.2971\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0894e-05 - val_loss: 0.2972\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.0799e-05 - val_loss: 0.2976\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0488e-05 - val_loss: 0.2981\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0364e-05 - val_loss: 0.2983\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0118e-05 - val_loss: 0.2986\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0191e-05 - val_loss: 0.2986\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9917e-05 - val_loss: 0.2986\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0101e-05 - val_loss: 0.2992\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9664e-05 - val_loss: 0.2996\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.9370e-05 - val_loss: 0.3002\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9006e-05 - val_loss: 0.3007\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.8857e-05 - val_loss: 0.3006\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8642e-05 - val_loss: 0.3010\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.8566e-05 - val_loss: 0.3010\n",
      "Epoch 475/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8238e-05 - val_loss: 0.3016\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8332e-05 - val_loss: 0.3020\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8036e-05 - val_loss: 0.3021\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7762e-05 - val_loss: 0.3025\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7743e-05 - val_loss: 0.3027\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7497e-05 - val_loss: 0.3033\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7436e-05 - val_loss: 0.3036\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7196e-05 - val_loss: 0.3038\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7192e-05 - val_loss: 0.3040\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6984e-05 - val_loss: 0.3045\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6729e-05 - val_loss: 0.3045\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6582e-05 - val_loss: 0.3049\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.6689e-05 - val_loss: 0.3054\n",
      "Epoch 488/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.6336e-05 - val_loss: 0.3058\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6230e-05 - val_loss: 0.3058\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6118e-05 - val_loss: 0.3059\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5885e-05 - val_loss: 0.3064\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5890e-05 - val_loss: 0.3067\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5978e-05 - val_loss: 0.3069\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5971e-05 - val_loss: 0.3071\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5684e-05 - val_loss: 0.3073\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5333e-05 - val_loss: 0.3076\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5096e-05 - val_loss: 0.3080\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4898e-05 - val_loss: 0.3085\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.4896e-05 - val_loss: 0.3089\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.4686e-05 - val_loss: 0.3090\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4709e-05 - val_loss: 0.3091\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4861e-05 - val_loss: 0.3090\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4570e-05 - val_loss: 0.3096\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4181e-05 - val_loss: 0.3101\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4253e-05 - val_loss: 0.3106\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4026e-05 - val_loss: 0.3110\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3761e-05 - val_loss: 0.3114\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3621e-05 - val_loss: 0.3117\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3661e-05 - val_loss: 0.3121\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.3773e-05 - val_loss: 0.3125\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3468e-05 - val_loss: 0.3126\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3251e-05 - val_loss: 0.3129\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.3072e-05 - val_loss: 0.3132\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3197e-05 - val_loss: 0.3134\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.3021e-05 - val_loss: 0.3137\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2900e-05 - val_loss: 0.3138\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2649e-05 - val_loss: 0.3141\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2619e-05 - val_loss: 0.3145\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2462e-05 - val_loss: 0.3147\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2343e-05 - val_loss: 0.3150\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2208e-05 - val_loss: 0.3153\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2205e-05 - val_loss: 0.3157\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2072e-05 - val_loss: 0.3159\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1918e-05 - val_loss: 0.3162\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1797e-05 - val_loss: 0.3164\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1805e-05 - val_loss: 0.3167\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1717e-05 - val_loss: 0.3168\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1543e-05 - val_loss: 0.3172\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1407e-05 - val_loss: 0.3173\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1307e-05 - val_loss: 0.3176\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1345e-05 - val_loss: 0.3180\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1127e-05 - val_loss: 0.3184\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1097e-05 - val_loss: 0.3185\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0929e-05 - val_loss: 0.3189\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0915e-05 - val_loss: 0.3193\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0807e-05 - val_loss: 0.3198\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0643e-05 - val_loss: 0.3200\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0533e-05 - val_loss: 0.3203\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0469e-05 - val_loss: 0.3207\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0352e-05 - val_loss: 0.3211\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0264e-05 - val_loss: 0.3215\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0270e-05 - val_loss: 0.3219\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0131e-05 - val_loss: 0.3219\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0053e-05 - val_loss: 0.3222\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.9689e-06 - val_loss: 0.3224\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.8721e-06 - val_loss: 0.3227\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.7746e-06 - val_loss: 0.3229\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.7535e-06 - val_loss: 0.3232\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.6235e-06 - val_loss: 0.3235\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5457e-06 - val_loss: 0.3235\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4572e-06 - val_loss: 0.3239\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.3959e-06 - val_loss: 0.3241\n",
      "Epoch 553/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 9.2960e-06 - val_loss: 0.3243\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2394e-06 - val_loss: 0.3247\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2018e-06 - val_loss: 0.3251\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1221e-06 - val_loss: 0.3252\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1085e-06 - val_loss: 0.3254\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.9457e-06 - val_loss: 0.3257\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.8901e-06 - val_loss: 0.3258\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.8177e-06 - val_loss: 0.3261\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.7875e-06 - val_loss: 0.3263\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.6596e-06 - val_loss: 0.3267\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.6318e-06 - val_loss: 0.3271\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5031e-06 - val_loss: 0.3274\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4735e-06 - val_loss: 0.3276\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.3640e-06 - val_loss: 0.3279\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.3491e-06 - val_loss: 0.3282\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.2316e-06 - val_loss: 0.3286\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1846e-06 - val_loss: 0.3288\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0891e-06 - val_loss: 0.3289\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0410e-06 - val_loss: 0.3291\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9659e-06 - val_loss: 0.3294\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9431e-06 - val_loss: 0.3298\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.8379e-06 - val_loss: 0.3300\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7652e-06 - val_loss: 0.3301\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7217e-06 - val_loss: 0.3303\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.6292e-06 - val_loss: 0.3307\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7349e-06 - val_loss: 0.3309\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.5087e-06 - val_loss: 0.3312\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6261e-06 - val_loss: 0.3316\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4660e-06 - val_loss: 0.3318\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3350e-06 - val_loss: 0.3320\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.3458e-06 - val_loss: 0.3324\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.2209e-06 - val_loss: 0.3327\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.1592e-06 - val_loss: 0.3331\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.1682e-06 - val_loss: 0.3334\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0255e-06 - val_loss: 0.3336\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.9886e-06 - val_loss: 0.3340\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.9408e-06 - val_loss: 0.3346\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8360e-06 - val_loss: 0.3349\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.9161e-06 - val_loss: 0.3351\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8275e-06 - val_loss: 0.3355\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7055e-06 - val_loss: 0.3358\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6511e-06 - val_loss: 0.3362\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5943e-06 - val_loss: 0.3365\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5384e-06 - val_loss: 0.3366\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5117e-06 - val_loss: 0.3368\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4299e-06 - val_loss: 0.3371\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3657e-06 - val_loss: 0.3372\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3537e-06 - val_loss: 0.3375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2a0439d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.initilize the ANN model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#2.Pass hidden layer\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "\n",
    "#3.Pass Activation function\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "#4.to establish the connection between layers\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")\n",
    "\n",
    "#5.train the model\n",
    "\n",
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1669204763610,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "6an0ksXSp_vR",
    "outputId": "2dd568fa-0cec-401f-d744-56afe25985a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6550126671791077,\n",
       "  0.4592512845993042,\n",
       "  0.3425174355506897,\n",
       "  0.26402777433395386,\n",
       "  0.20820030570030212,\n",
       "  0.1703035682439804,\n",
       "  0.14551499485969543,\n",
       "  0.12719999253749847,\n",
       "  0.11435549706220627,\n",
       "  0.10280439257621765,\n",
       "  0.09394059330224991,\n",
       "  0.08677810430526733,\n",
       "  0.08078651875257492,\n",
       "  0.07549812644720078,\n",
       "  0.0711241215467453,\n",
       "  0.06764064729213715,\n",
       "  0.06403917819261551,\n",
       "  0.060884494334459305,\n",
       "  0.05811905488371849,\n",
       "  0.05551300197839737,\n",
       "  0.053119927644729614,\n",
       "  0.05034791678190231,\n",
       "  0.048264458775520325,\n",
       "  0.04640292748808861,\n",
       "  0.04453127086162567,\n",
       "  0.042195823043584824,\n",
       "  0.04030829668045044,\n",
       "  0.03865998983383179,\n",
       "  0.03719712793827057,\n",
       "  0.03586580231785774,\n",
       "  0.03427926078438759,\n",
       "  0.032720740884542465,\n",
       "  0.031237466260790825,\n",
       "  0.03008507937192917,\n",
       "  0.02893958054482937,\n",
       "  0.027652304619550705,\n",
       "  0.026586508378386497,\n",
       "  0.025629661977291107,\n",
       "  0.02449043095111847,\n",
       "  0.023576859384775162,\n",
       "  0.022788384929299355,\n",
       "  0.021822310984134674,\n",
       "  0.020742064341902733,\n",
       "  0.019861003383994102,\n",
       "  0.019039403647184372,\n",
       "  0.018643023446202278,\n",
       "  0.017825234681367874,\n",
       "  0.017097527161240578,\n",
       "  0.016329841688275337,\n",
       "  0.015751829370856285,\n",
       "  0.015237072482705116,\n",
       "  0.01460383553057909,\n",
       "  0.014048481360077858,\n",
       "  0.013488070107996464,\n",
       "  0.013171243481338024,\n",
       "  0.012545079924166203,\n",
       "  0.012069746851921082,\n",
       "  0.011513059027493,\n",
       "  0.011211908422410488,\n",
       "  0.010739920660853386,\n",
       "  0.010406103916466236,\n",
       "  0.010104676708579063,\n",
       "  0.00971967726945877,\n",
       "  0.009267737157642841,\n",
       "  0.008887648582458496,\n",
       "  0.008419109508395195,\n",
       "  0.008164376020431519,\n",
       "  0.007864595390856266,\n",
       "  0.00775792496278882,\n",
       "  0.007639209274202585,\n",
       "  0.007208035793155432,\n",
       "  0.006851959973573685,\n",
       "  0.006685843225568533,\n",
       "  0.006357506848871708,\n",
       "  0.006247145589441061,\n",
       "  0.005970603320747614,\n",
       "  0.0057546962052583694,\n",
       "  0.00553485844284296,\n",
       "  0.005401143338531256,\n",
       "  0.00523556349799037,\n",
       "  0.005098840221762657,\n",
       "  0.004938862286508083,\n",
       "  0.004800301976501942,\n",
       "  0.004628345835953951,\n",
       "  0.004429578315466642,\n",
       "  0.004368301015347242,\n",
       "  0.0041681150905787945,\n",
       "  0.004053972195833921,\n",
       "  0.003996809013187885,\n",
       "  0.003849984612315893,\n",
       "  0.0037841314915567636,\n",
       "  0.0036740207578986883,\n",
       "  0.003524714382365346,\n",
       "  0.00344676710665226,\n",
       "  0.003385991556569934,\n",
       "  0.0032666209153831005,\n",
       "  0.00318193924613297,\n",
       "  0.0030921397265046835,\n",
       "  0.003029638435691595,\n",
       "  0.002918181475251913,\n",
       "  0.0028536473400890827,\n",
       "  0.002768924692645669,\n",
       "  0.0026672326494008303,\n",
       "  0.002724520629271865,\n",
       "  0.0025464817881584167,\n",
       "  0.0025204543489962816,\n",
       "  0.002407489577308297,\n",
       "  0.0023553206119686365,\n",
       "  0.002274281345307827,\n",
       "  0.0022165344562381506,\n",
       "  0.002162568038329482,\n",
       "  0.0021085997577756643,\n",
       "  0.0021300558000802994,\n",
       "  0.00201680907048285,\n",
       "  0.0019644596613943577,\n",
       "  0.0019161476520821452,\n",
       "  0.0018965161871165037,\n",
       "  0.0018741395324468613,\n",
       "  0.0017871730960905552,\n",
       "  0.001766237081028521,\n",
       "  0.0017305082874372602,\n",
       "  0.0016710505587980151,\n",
       "  0.0016679841792210937,\n",
       "  0.0015896894037723541,\n",
       "  0.0015903448220342398,\n",
       "  0.0015303000109270215,\n",
       "  0.0014875836204737425,\n",
       "  0.0014895525528118014,\n",
       "  0.0014300227630883455,\n",
       "  0.0014362483052536845,\n",
       "  0.0013849807437509298,\n",
       "  0.0013460860354825854,\n",
       "  0.001315593020990491,\n",
       "  0.001280276570469141,\n",
       "  0.0012714387848973274,\n",
       "  0.0012406394816935062,\n",
       "  0.0012099990854039788,\n",
       "  0.0011936082737520337,\n",
       "  0.0011633363319560885,\n",
       "  0.0011265500215813518,\n",
       "  0.0011453113984316587,\n",
       "  0.0010800702730193734,\n",
       "  0.0010633673518896103,\n",
       "  0.0010519612114876509,\n",
       "  0.0010215026559308171,\n",
       "  0.0010087190894410014,\n",
       "  0.000981590012088418,\n",
       "  0.0009676769841462374,\n",
       "  0.0009422380826435983,\n",
       "  0.0009479260770604014,\n",
       "  0.0009306760039180517,\n",
       "  0.0009484338224865496,\n",
       "  0.0009097232250496745,\n",
       "  0.0008693874115124345,\n",
       "  0.0008431744063273072,\n",
       "  0.0008195068803615868,\n",
       "  0.0008064573048613966,\n",
       "  0.0007934379973448813,\n",
       "  0.0007724291644990444,\n",
       "  0.0007618879899382591,\n",
       "  0.0007462164503522217,\n",
       "  0.0007350058876909316,\n",
       "  0.0007392556872218847,\n",
       "  0.0007088033016771078,\n",
       "  0.0006959071615710855,\n",
       "  0.0006920858286321163,\n",
       "  0.0006772548076696694,\n",
       "  0.0006608468829654157,\n",
       "  0.0006518251029774547,\n",
       "  0.0006419495912268758,\n",
       "  0.0006255056941881776,\n",
       "  0.0006245510303415358,\n",
       "  0.0006011613295413554,\n",
       "  0.0005970753845758736,\n",
       "  0.0005928316386416554,\n",
       "  0.0005666319048032165,\n",
       "  0.0005597533308900893,\n",
       "  0.0005507973255589604,\n",
       "  0.0005503030261024833,\n",
       "  0.0005351176951080561,\n",
       "  0.0005244511994533241,\n",
       "  0.0005243647610768676,\n",
       "  0.0005116364918649197,\n",
       "  0.0004993223701603711,\n",
       "  0.0004949176218360662,\n",
       "  0.0004902051296085119,\n",
       "  0.0004730718210339546,\n",
       "  0.00046760551049374044,\n",
       "  0.00046254717744886875,\n",
       "  0.00045400220551528037,\n",
       "  0.00044404593063518405,\n",
       "  0.0004370396491140127,\n",
       "  0.0004283798043616116,\n",
       "  0.0004297758569009602,\n",
       "  0.00042409190791659057,\n",
       "  0.000419215444708243,\n",
       "  0.00040767499012872577,\n",
       "  0.00040147313848137856,\n",
       "  0.00040005994378589094,\n",
       "  0.0004060523060616106,\n",
       "  0.0003982744528912008,\n",
       "  0.0003847569751087576,\n",
       "  0.00037198016070760787,\n",
       "  0.00036603654734790325,\n",
       "  0.00035915416083298624,\n",
       "  0.00035069449222646654,\n",
       "  0.00034549867268651724,\n",
       "  0.00033946489566005766,\n",
       "  0.0003330021572764963,\n",
       "  0.0003338861861266196,\n",
       "  0.00032494592596776783,\n",
       "  0.0003202304942533374,\n",
       "  0.0003163026412948966,\n",
       "  0.0003114734427072108,\n",
       "  0.00030585622880607843,\n",
       "  0.000302160216961056,\n",
       "  0.0002993377856910229,\n",
       "  0.0002964894229080528,\n",
       "  0.0002900953986681998,\n",
       "  0.00028826852212660015,\n",
       "  0.0002852968464139849,\n",
       "  0.00027974756085313857,\n",
       "  0.0002752872824203223,\n",
       "  0.0002726555394474417,\n",
       "  0.00027123905601911247,\n",
       "  0.00026774167781695724,\n",
       "  0.00027133754338137805,\n",
       "  0.00026380392955616117,\n",
       "  0.0002545749593991786,\n",
       "  0.0002525856252759695,\n",
       "  0.0002498173853382468,\n",
       "  0.00024362941621802747,\n",
       "  0.00023914489429444075,\n",
       "  0.00024183691130019724,\n",
       "  0.00023897647042758763,\n",
       "  0.00023335317382588983,\n",
       "  0.00022601669479627162,\n",
       "  0.00022316211834549904,\n",
       "  0.00021746396669186652,\n",
       "  0.00021436928363982588,\n",
       "  0.00021205999655649066,\n",
       "  0.00021097739227116108,\n",
       "  0.0002068023750325665,\n",
       "  0.00020434195175766945,\n",
       "  0.0002008050651056692,\n",
       "  0.00019966955005656928,\n",
       "  0.00019701816199813038,\n",
       "  0.0001948246208485216,\n",
       "  0.0001916791225085035,\n",
       "  0.000190636477782391,\n",
       "  0.00018759227532427758,\n",
       "  0.00018552696565166116,\n",
       "  0.00018471827206667513,\n",
       "  0.00017980823758989573,\n",
       "  0.00017904241394717246,\n",
       "  0.00017621455481275916,\n",
       "  0.00017311774718109518,\n",
       "  0.00017336764722131193,\n",
       "  0.0001692195946816355,\n",
       "  0.00016563171811867505,\n",
       "  0.00016545277321711183,\n",
       "  0.00016169641457963735,\n",
       "  0.00015998682647477835,\n",
       "  0.00015793398779351264,\n",
       "  0.000157554357429035,\n",
       "  0.00015919480938464403,\n",
       "  0.00015836085367482156,\n",
       "  0.00015400011034216732,\n",
       "  0.00014913429913576692,\n",
       "  0.00014652677054982632,\n",
       "  0.0001462125510443002,\n",
       "  0.00014196778647601604,\n",
       "  0.00014079068205319345,\n",
       "  0.0001402368361596018,\n",
       "  0.00013801950262859464,\n",
       "  0.0001358561567030847,\n",
       "  0.00013597725774161518,\n",
       "  0.0001324669865425676,\n",
       "  0.00013277096149977297,\n",
       "  0.00013051627320237458,\n",
       "  0.0001281833101529628,\n",
       "  0.00012805366714019328,\n",
       "  0.00012578019232023507,\n",
       "  0.00012374781363178045,\n",
       "  0.0001229561894433573,\n",
       "  0.00012127982336096466,\n",
       "  0.00012152562703704461,\n",
       "  0.00011968918988713995,\n",
       "  0.00011750030535040423,\n",
       "  0.0001163887427537702,\n",
       "  0.00011437801003921777,\n",
       "  0.00011314069706713781,\n",
       "  0.00011266718502156436,\n",
       "  0.0001105805131373927,\n",
       "  0.00011037498916266486,\n",
       "  0.00010853430285351351,\n",
       "  0.00010714784730225801,\n",
       "  0.00010725447646109387,\n",
       "  0.00010520932846702635,\n",
       "  0.00010357364953961223,\n",
       "  0.0001019654082483612,\n",
       "  0.00010151963942917064,\n",
       "  9.976563887903467e-05,\n",
       "  9.857406257651746e-05,\n",
       "  9.796656377147883e-05,\n",
       "  9.656523616285995e-05,\n",
       "  9.650164429331198e-05,\n",
       "  9.492048411630094e-05,\n",
       "  9.419782873010263e-05,\n",
       "  9.273795876652002e-05,\n",
       "  9.157014574157074e-05,\n",
       "  9.045964543474838e-05,\n",
       "  9.067657083505765e-05,\n",
       "  8.886935393093154e-05,\n",
       "  8.803923265077174e-05,\n",
       "  8.722460188437253e-05,\n",
       "  8.608915959484875e-05,\n",
       "  8.590630750404671e-05,\n",
       "  8.402104867855087e-05,\n",
       "  8.306077506858855e-05,\n",
       "  8.285427611554042e-05,\n",
       "  8.242390322266147e-05,\n",
       "  8.195226109819487e-05,\n",
       "  7.973369065439329e-05,\n",
       "  7.912686851341277e-05,\n",
       "  7.862162601668388e-05,\n",
       "  7.740758883301169e-05,\n",
       "  7.677522080484778e-05,\n",
       "  7.503028609789908e-05,\n",
       "  7.446463860105723e-05,\n",
       "  7.358349830610678e-05,\n",
       "  7.29475577827543e-05,\n",
       "  7.197563536465168e-05,\n",
       "  7.205393194453791e-05,\n",
       "  7.177193037932739e-05,\n",
       "  7.079671922838315e-05,\n",
       "  6.931943789822981e-05,\n",
       "  6.820778799010441e-05,\n",
       "  6.857184780528769e-05,\n",
       "  6.758720701327547e-05,\n",
       "  6.663262320216745e-05,\n",
       "  6.562208727700636e-05,\n",
       "  6.513647531392053e-05,\n",
       "  6.426865729736164e-05,\n",
       "  6.372829375322908e-05,\n",
       "  6.312862387858331e-05,\n",
       "  6.262602255446836e-05,\n",
       "  6.218268390512094e-05,\n",
       "  6.123463390395045e-05,\n",
       "  6.0842798120575026e-05,\n",
       "  5.976929605822079e-05,\n",
       "  6.0054306231904775e-05,\n",
       "  5.924987999605946e-05,\n",
       "  5.883041012566537e-05,\n",
       "  5.730555858463049e-05,\n",
       "  5.773973316536285e-05,\n",
       "  5.6609675084473565e-05,\n",
       "  5.636678542941809e-05,\n",
       "  5.5304910347331315e-05,\n",
       "  5.478301318362355e-05,\n",
       "  5.418123691924848e-05,\n",
       "  5.347721162252128e-05,\n",
       "  5.311048880685121e-05,\n",
       "  5.319322008290328e-05,\n",
       "  5.195961784920655e-05,\n",
       "  5.155236431164667e-05,\n",
       "  5.182706081541255e-05,\n",
       "  5.023885751143098e-05,\n",
       "  5.023236735723913e-05,\n",
       "  4.930828436044976e-05,\n",
       "  4.935798278893344e-05,\n",
       "  4.849125616601668e-05,\n",
       "  4.800582610187121e-05,\n",
       "  4.824602001463063e-05,\n",
       "  4.725944745587185e-05,\n",
       "  4.68396428914275e-05,\n",
       "  4.6328310418175533e-05,\n",
       "  4.5553450036095455e-05,\n",
       "  4.515630644164048e-05,\n",
       "  4.478032496990636e-05,\n",
       "  4.41898955614306e-05,\n",
       "  4.40943222201895e-05,\n",
       "  4.37795024481602e-05,\n",
       "  4.2944921005982906e-05,\n",
       "  4.281152359908447e-05,\n",
       "  4.221007111482322e-05,\n",
       "  4.19410462200176e-05,\n",
       "  4.1378993046237156e-05,\n",
       "  4.124919723835774e-05,\n",
       "  4.040022031404078e-05,\n",
       "  3.9995073166210204e-05,\n",
       "  3.993622522102669e-05,\n",
       "  3.9638503949390724e-05,\n",
       "  3.903102333424613e-05,\n",
       "  3.8786001823609695e-05,\n",
       "  3.85279199690558e-05,\n",
       "  3.7853904359508306e-05,\n",
       "  3.753303099074401e-05,\n",
       "  3.733050834853202e-05,\n",
       "  3.704148912220262e-05,\n",
       "  3.6434572393773124e-05,\n",
       "  3.6456287489272654e-05,\n",
       "  3.56410673703067e-05,\n",
       "  3.5510118323145434e-05,\n",
       "  3.509990347083658e-05,\n",
       "  3.474270852166228e-05,\n",
       "  3.437825580476783e-05,\n",
       "  3.4156706533394754e-05,\n",
       "  3.369215482962318e-05,\n",
       "  3.378988185431808e-05,\n",
       "  3.333229687996209e-05,\n",
       "  3.281056706327945e-05,\n",
       "  3.2551688491366804e-05,\n",
       "  3.2228243071585894e-05,\n",
       "  3.205071698175743e-05,\n",
       "  3.159581683576107e-05,\n",
       "  3.122352427453734e-05,\n",
       "  3.1248178856913e-05,\n",
       "  3.071413448196836e-05,\n",
       "  3.039187504327856e-05,\n",
       "  3.0253073418862186e-05,\n",
       "  2.98792638204759e-05,\n",
       "  2.9832091968273744e-05,\n",
       "  2.9362174245761707e-05,\n",
       "  2.918209611380007e-05,\n",
       "  2.880327338061761e-05,\n",
       "  2.8922208002768457e-05,\n",
       "  2.817361382767558e-05,\n",
       "  2.8736854801536538e-05,\n",
       "  2.8281927370699123e-05,\n",
       "  2.7537020287127234e-05,\n",
       "  2.7235835659666918e-05,\n",
       "  2.7067584596807137e-05,\n",
       "  2.7150186724611558e-05,\n",
       "  2.6666557459975593e-05,\n",
       "  2.614954973978456e-05,\n",
       "  2.6133411665796302e-05,\n",
       "  2.5691384507808834e-05,\n",
       "  2.538076114433352e-05,\n",
       "  2.5433926566620357e-05,\n",
       "  2.4977893190225586e-05,\n",
       "  2.489032340236008e-05,\n",
       "  2.450909960316494e-05,\n",
       "  2.4443434085696936e-05,\n",
       "  2.409093576716259e-05,\n",
       "  2.3918404622236267e-05,\n",
       "  2.3648504793527536e-05,\n",
       "  2.3655633413000032e-05,\n",
       "  2.3280281311599538e-05,\n",
       "  2.3063787011778913e-05,\n",
       "  2.3102991690393537e-05,\n",
       "  2.2691634512739256e-05,\n",
       "  2.248054079245776e-05,\n",
       "  2.233350824099034e-05,\n",
       "  2.2089958292781375e-05,\n",
       "  2.187461177527439e-05,\n",
       "  2.168500577681698e-05,\n",
       "  2.1418240066850558e-05,\n",
       "  2.13735293073114e-05,\n",
       "  2.1063357053208165e-05,\n",
       "  2.089440204144921e-05,\n",
       "  2.079944715660531e-05,\n",
       "  2.0487837900873274e-05,\n",
       "  2.0363910152809694e-05,\n",
       "  2.0117982785450295e-05,\n",
       "  2.0190675058984198e-05,\n",
       "  1.991701719816774e-05,\n",
       "  2.0101355403312482e-05,\n",
       "  1.9664175852085464e-05,\n",
       "  1.9369565052329563e-05,\n",
       "  1.900628922157921e-05,\n",
       "  1.8856893802876584e-05,\n",
       "  1.8642198483576067e-05,\n",
       "  1.8566419385024346e-05,\n",
       "  1.823829734348692e-05,\n",
       "  1.8331611499888822e-05,\n",
       "  1.8035803805105388e-05,\n",
       "  1.776172939571552e-05,\n",
       "  1.7743028365657665e-05,\n",
       "  1.749703733366914e-05,\n",
       "  1.7435630070394836e-05,\n",
       "  1.7196200133184902e-05,\n",
       "  1.7192360246554017e-05,\n",
       "  1.6984384274110198e-05,\n",
       "  1.6729251001379453e-05,\n",
       "  1.6581789168412797e-05,\n",
       "  1.668926779530011e-05,\n",
       "  1.6335901818820275e-05,\n",
       "  1.62302385433577e-05,\n",
       "  1.6117532140924595e-05,\n",
       "  1.588549457665067e-05,\n",
       "  1.5889661881374195e-05,\n",
       "  1.597771915839985e-05,\n",
       "  1.597054688318167e-05,\n",
       "  1.5684132449678145e-05,\n",
       "  1.53326091094641e-05,\n",
       "  1.5095539311005268e-05,\n",
       "  1.4898056178935803e-05,\n",
       "  1.489558144385228e-05,\n",
       "  1.468616937927436e-05,\n",
       "  1.4709155038872268e-05,\n",
       "  1.4860727787890937e-05,\n",
       "  1.4570306120731402e-05,\n",
       "  1.4181452570483088e-05,\n",
       "  1.4252821529225912e-05,\n",
       "  1.4025520613358822e-05,\n",
       "  1.3761218724539503e-05,\n",
       "  1.362092916679103e-05,\n",
       "  1.366059404972475e-05,\n",
       "  1.3772541933576576e-05,\n",
       "  1.3468239558278583e-05,\n",
       "  1.3251326890895143e-05,\n",
       "  1.307187085330952e-05,\n",
       "  1.3196980034990702e-05,\n",
       "  1.3021498489251826e-05,\n",
       "  1.2900487490696833e-05,\n",
       "  1.2648720257857349e-05,\n",
       "  1.2619376320799347e-05,\n",
       "  1.2462426639103796e-05,\n",
       "  1.234297360497294e-05,\n",
       "  1.2208434782223776e-05,\n",
       "  1.220456852024654e-05,\n",
       "  1.207180685014464e-05,\n",
       "  1.1917644769710023e-05,\n",
       "  1.1796810213127173e-05,\n",
       "  1.1804774658230599e-05,\n",
       "  1.1717149391188286e-05,\n",
       "  1.1543025721039157e-05,\n",
       "  1.1407162674004212e-05,\n",
       "  1.1307321983622387e-05,\n",
       "  1.13448286356288e-05,\n",
       "  1.1126840945507865e-05,\n",
       "  1.1096773960161954e-05,\n",
       "  1.092856746254256e-05,\n",
       "  1.091547073883703e-05,\n",
       "  1.0807287253555842e-05,\n",
       "  1.0642571396601852e-05,\n",
       "  1.0532973647059407e-05,\n",
       "  1.0468883374414872e-05,\n",
       "  1.0351620403525885e-05,\n",
       "  1.0263878721161745e-05,\n",
       "  1.0269768608850427e-05,\n",
       "  1.0131489943887573e-05,\n",
       "  1.005303147394443e-05,\n",
       "  9.968923222913872e-06,\n",
       "  9.872130249277689e-06,\n",
       "  9.774556019692682e-06,\n",
       "  9.753474842000287e-06,\n",
       "  9.623528967495076e-06,\n",
       "  9.545719876768999e-06,\n",
       "  9.457191481487826e-06,\n",
       "  9.39594247029163e-06,\n",
       "  9.295992640545592e-06,\n",
       "  9.239382052328438e-06,\n",
       "  9.201819011650514e-06,\n",
       "  9.122107258008327e-06,\n",
       "  9.10848848434398e-06,\n",
       "  8.945710760599468e-06,\n",
       "  8.89013426785823e-06,\n",
       "  8.81771029526135e-06,\n",
       "  8.787468686932698e-06,\n",
       "  8.659557352075353e-06,\n",
       "  8.631754099042155e-06,\n",
       "  8.503138815285638e-06,\n",
       "  8.473451998725068e-06,\n",
       "  8.364037967112381e-06,\n",
       "  8.349091331183445e-06,\n",
       "  8.23158370621968e-06,\n",
       "  8.184602847904898e-06,\n",
       "  8.089060429483652e-06,\n",
       "  8.040968168643303e-06,\n",
       "  7.96587482909672e-06,\n",
       "  7.94312381913187e-06,\n",
       "  7.837879820726812e-06,\n",
       "  7.765222107991576e-06,\n",
       "  7.721651854808442e-06,\n",
       "  7.629167612321908e-06,\n",
       "  7.734943210380152e-06,\n",
       "  7.5087082223035395e-06,\n",
       "  7.6260639616521075e-06,\n",
       "  7.466015176760266e-06,\n",
       "  7.335041118494701e-06,\n",
       "  7.345816356973955e-06,\n",
       "  7.220873158075847e-06,\n",
       "  7.159234428399941e-06,\n",
       "  7.168197498685913e-06,\n",
       "  7.0254627644317225e-06,\n",
       "  6.988575023569865e-06,\n",
       "  6.940783350728452e-06,\n",
       "  6.836002285126597e-06,\n",
       "  6.916064648976317e-06,\n",
       "  6.827467132097809e-06,\n",
       "  6.7055375438940246e-06,\n",
       "  6.65113248032867e-06,\n",
       "  6.59429861116223e-06,\n",
       "  6.538424258906161e-06,\n",
       "  6.51167601972702e-06,\n",
       "  6.4299279074475635e-06,\n",
       "  6.3656502788944636e-06,\n",
       "  6.353733624564484e-06],\n",
       " 'val_loss': [0.5372860431671143,\n",
       "  0.396709144115448,\n",
       "  0.3151087462902069,\n",
       "  0.261520653963089,\n",
       "  0.2237502485513687,\n",
       "  0.19614914059638977,\n",
       "  0.1753760278224945,\n",
       "  0.16004082560539246,\n",
       "  0.1476888656616211,\n",
       "  0.13772310316562653,\n",
       "  0.13063131272792816,\n",
       "  0.12570540606975555,\n",
       "  0.12095260620117188,\n",
       "  0.11769551038742065,\n",
       "  0.11536286026239395,\n",
       "  0.1138317734003067,\n",
       "  0.11220895498991013,\n",
       "  0.11050624400377274,\n",
       "  0.10950256884098053,\n",
       "  0.10886117815971375,\n",
       "  0.10720019787549973,\n",
       "  0.1076655462384224,\n",
       "  0.10685238987207413,\n",
       "  0.10628442466259003,\n",
       "  0.10695744305849075,\n",
       "  0.10684634745121002,\n",
       "  0.10745382308959961,\n",
       "  0.10611798614263535,\n",
       "  0.10559649020433426,\n",
       "  0.10791850835084915,\n",
       "  0.10685752332210541,\n",
       "  0.10683143138885498,\n",
       "  0.10787050426006317,\n",
       "  0.10603611171245575,\n",
       "  0.10716520994901657,\n",
       "  0.10712459683418274,\n",
       "  0.10769594460725784,\n",
       "  0.10729788988828659,\n",
       "  0.10817299038171768,\n",
       "  0.10906165093183517,\n",
       "  0.11011142283678055,\n",
       "  0.1106732040643692,\n",
       "  0.11144315451383591,\n",
       "  0.11081518977880478,\n",
       "  0.1105295717716217,\n",
       "  0.11284029483795166,\n",
       "  0.11376041918992996,\n",
       "  0.11420433223247528,\n",
       "  0.11426182836294174,\n",
       "  0.11489669978618622,\n",
       "  0.11616381257772446,\n",
       "  0.11622090637683868,\n",
       "  0.11723879724740982,\n",
       "  0.11708085238933563,\n",
       "  0.11590313166379929,\n",
       "  0.11737576127052307,\n",
       "  0.11864320933818817,\n",
       "  0.11890824884176254,\n",
       "  0.11943323165178299,\n",
       "  0.12038020044565201,\n",
       "  0.12037008255720139,\n",
       "  0.1223154217004776,\n",
       "  0.12149912118911743,\n",
       "  0.11979807168245316,\n",
       "  0.12147106230258942,\n",
       "  0.12267353385686874,\n",
       "  0.1226302832365036,\n",
       "  0.12354367971420288,\n",
       "  0.12429172545671463,\n",
       "  0.12436021119356155,\n",
       "  0.12622641026973724,\n",
       "  0.12608285248279572,\n",
       "  0.1268054097890854,\n",
       "  0.12788937985897064,\n",
       "  0.12844912707805634,\n",
       "  0.12890058755874634,\n",
       "  0.12978322803974152,\n",
       "  0.1309964656829834,\n",
       "  0.13091394305229187,\n",
       "  0.13097494840621948,\n",
       "  0.13242053985595703,\n",
       "  0.13257963955402374,\n",
       "  0.13391709327697754,\n",
       "  0.13423487544059753,\n",
       "  0.13463912904262543,\n",
       "  0.13508114218711853,\n",
       "  0.135901540517807,\n",
       "  0.13666820526123047,\n",
       "  0.13716550171375275,\n",
       "  0.13724862039089203,\n",
       "  0.1389702558517456,\n",
       "  0.1393594890832901,\n",
       "  0.13948655128479004,\n",
       "  0.13926607370376587,\n",
       "  0.1398250013589859,\n",
       "  0.14027194678783417,\n",
       "  0.14190369844436646,\n",
       "  0.14189593493938446,\n",
       "  0.14316096901893616,\n",
       "  0.14337372779846191,\n",
       "  0.1446850597858429,\n",
       "  0.1454673856496811,\n",
       "  0.14582866430282593,\n",
       "  0.14579054713249207,\n",
       "  0.14738360047340393,\n",
       "  0.14851351082324982,\n",
       "  0.1485949456691742,\n",
       "  0.14833185076713562,\n",
       "  0.14857742190361023,\n",
       "  0.14978671073913574,\n",
       "  0.15068712830543518,\n",
       "  0.1513032466173172,\n",
       "  0.15155048668384552,\n",
       "  0.15200074017047882,\n",
       "  0.15270011126995087,\n",
       "  0.1536826491355896,\n",
       "  0.15458299219608307,\n",
       "  0.15510568022727966,\n",
       "  0.15549510717391968,\n",
       "  0.15665702521800995,\n",
       "  0.15692687034606934,\n",
       "  0.15683574974536896,\n",
       "  0.15792281925678253,\n",
       "  0.15856824815273285,\n",
       "  0.15909495949745178,\n",
       "  0.15973323583602905,\n",
       "  0.16030076146125793,\n",
       "  0.16124922037124634,\n",
       "  0.16192637383937836,\n",
       "  0.16270233690738678,\n",
       "  0.16351573169231415,\n",
       "  0.16395245492458344,\n",
       "  0.16461867094039917,\n",
       "  0.1647137850522995,\n",
       "  0.16525956988334656,\n",
       "  0.16579309105873108,\n",
       "  0.16672615706920624,\n",
       "  0.1685691475868225,\n",
       "  0.16917569935321808,\n",
       "  0.16958169639110565,\n",
       "  0.16999872028827667,\n",
       "  0.17034493386745453,\n",
       "  0.1709006279706955,\n",
       "  0.1718376725912094,\n",
       "  0.17247815430164337,\n",
       "  0.172623872756958,\n",
       "  0.17334896326065063,\n",
       "  0.17382211983203888,\n",
       "  0.1746326982975006,\n",
       "  0.17505128681659698,\n",
       "  0.17605790495872498,\n",
       "  0.17637695372104645,\n",
       "  0.17693524062633514,\n",
       "  0.17753420770168304,\n",
       "  0.17784234881401062,\n",
       "  0.17863959074020386,\n",
       "  0.1794709712266922,\n",
       "  0.18017062544822693,\n",
       "  0.18048736453056335,\n",
       "  0.1811467856168747,\n",
       "  0.18176475167274475,\n",
       "  0.1824111044406891,\n",
       "  0.18302014470100403,\n",
       "  0.18356776237487793,\n",
       "  0.18401816487312317,\n",
       "  0.1844029277563095,\n",
       "  0.18554431200027466,\n",
       "  0.18590077757835388,\n",
       "  0.1864362508058548,\n",
       "  0.1866929531097412,\n",
       "  0.18731927871704102,\n",
       "  0.18771402537822723,\n",
       "  0.18807736039161682,\n",
       "  0.18899761140346527,\n",
       "  0.18941089510917664,\n",
       "  0.189651221036911,\n",
       "  0.19021804630756378,\n",
       "  0.19065770506858826,\n",
       "  0.19103199243545532,\n",
       "  0.191731259226799,\n",
       "  0.19211287796497345,\n",
       "  0.19291354715824127,\n",
       "  0.1932375431060791,\n",
       "  0.1937074065208435,\n",
       "  0.19414004683494568,\n",
       "  0.19482335448265076,\n",
       "  0.19537703692913055,\n",
       "  0.19590795040130615,\n",
       "  0.19612625241279602,\n",
       "  0.19707734882831573,\n",
       "  0.19745616614818573,\n",
       "  0.1977754831314087,\n",
       "  0.19840943813323975,\n",
       "  0.19903819262981415,\n",
       "  0.19940020143985748,\n",
       "  0.19979050755500793,\n",
       "  0.1998429149389267,\n",
       "  0.20105761289596558,\n",
       "  0.2016107141971588,\n",
       "  0.20242618024349213,\n",
       "  0.2026643604040146,\n",
       "  0.20317216217517853,\n",
       "  0.20395830273628235,\n",
       "  0.2046336978673935,\n",
       "  0.2050829827785492,\n",
       "  0.2050624042749405,\n",
       "  0.20592153072357178,\n",
       "  0.20632648468017578,\n",
       "  0.2067493200302124,\n",
       "  0.20731402933597565,\n",
       "  0.20772887766361237,\n",
       "  0.20802095532417297,\n",
       "  0.20871995389461517,\n",
       "  0.2092715948820114,\n",
       "  0.20931006968021393,\n",
       "  0.20993487536907196,\n",
       "  0.2102770060300827,\n",
       "  0.21052029728889465,\n",
       "  0.21110549569129944,\n",
       "  0.2117619812488556,\n",
       "  0.21245911717414856,\n",
       "  0.2127286046743393,\n",
       "  0.21309389173984528,\n",
       "  0.2134186327457428,\n",
       "  0.21409198641777039,\n",
       "  0.21428541839122772,\n",
       "  0.21438391506671906,\n",
       "  0.21469762921333313,\n",
       "  0.21539315581321716,\n",
       "  0.21607621014118195,\n",
       "  0.21658702194690704,\n",
       "  0.2168559730052948,\n",
       "  0.2177221029996872,\n",
       "  0.2183219939470291,\n",
       "  0.2183624655008316,\n",
       "  0.2187168002128601,\n",
       "  0.21947985887527466,\n",
       "  0.21994076669216156,\n",
       "  0.22082491219043732,\n",
       "  0.2211042195558548,\n",
       "  0.22154290974140167,\n",
       "  0.22170907258987427,\n",
       "  0.22217734158039093,\n",
       "  0.2224637269973755,\n",
       "  0.22327035665512085,\n",
       "  0.2237372100353241,\n",
       "  0.2239992469549179,\n",
       "  0.22424474358558655,\n",
       "  0.22479359805583954,\n",
       "  0.2251245379447937,\n",
       "  0.2255311906337738,\n",
       "  0.22635391354560852,\n",
       "  0.22648072242736816,\n",
       "  0.2265753298997879,\n",
       "  0.2272540032863617,\n",
       "  0.22751367092132568,\n",
       "  0.22825004160404205,\n",
       "  0.22874575853347778,\n",
       "  0.2292308509349823,\n",
       "  0.22938546538352966,\n",
       "  0.23010505735874176,\n",
       "  0.23053060472011566,\n",
       "  0.23079989850521088,\n",
       "  0.23141415417194366,\n",
       "  0.23208299279212952,\n",
       "  0.23237456381320953,\n",
       "  0.23229661583900452,\n",
       "  0.23264949023723602,\n",
       "  0.2329527586698532,\n",
       "  0.23349210619926453,\n",
       "  0.23426687717437744,\n",
       "  0.2345178872346878,\n",
       "  0.2349889874458313,\n",
       "  0.23523765802383423,\n",
       "  0.2356729358434677,\n",
       "  0.2361501008272171,\n",
       "  0.23647065460681915,\n",
       "  0.23715229332447052,\n",
       "  0.23734666407108307,\n",
       "  0.23791354894638062,\n",
       "  0.23802870512008667,\n",
       "  0.23840932548046112,\n",
       "  0.23870377242565155,\n",
       "  0.23931951820850372,\n",
       "  0.23961472511291504,\n",
       "  0.23988525569438934,\n",
       "  0.24032941460609436,\n",
       "  0.24066072702407837,\n",
       "  0.24081626534461975,\n",
       "  0.24125221371650696,\n",
       "  0.24159717559814453,\n",
       "  0.24187205731868744,\n",
       "  0.24243253469467163,\n",
       "  0.2427719235420227,\n",
       "  0.2430221438407898,\n",
       "  0.24333281815052032,\n",
       "  0.24372383952140808,\n",
       "  0.24421405792236328,\n",
       "  0.24443455040454865,\n",
       "  0.2449948489665985,\n",
       "  0.24532604217529297,\n",
       "  0.2455196976661682,\n",
       "  0.2458190768957138,\n",
       "  0.24619978666305542,\n",
       "  0.24652940034866333,\n",
       "  0.24726994335651398,\n",
       "  0.24754127860069275,\n",
       "  0.2482399046421051,\n",
       "  0.24841775000095367,\n",
       "  0.24865032732486725,\n",
       "  0.24895957112312317,\n",
       "  0.24947111308574677,\n",
       "  0.2495945692062378,\n",
       "  0.24963684380054474,\n",
       "  0.2502000331878662,\n",
       "  0.2506701946258545,\n",
       "  0.250917911529541,\n",
       "  0.2514389455318451,\n",
       "  0.251747727394104,\n",
       "  0.252126008272171,\n",
       "  0.252263605594635,\n",
       "  0.252660870552063,\n",
       "  0.2531164586544037,\n",
       "  0.25331971049308777,\n",
       "  0.2536063492298126,\n",
       "  0.2539651691913605,\n",
       "  0.25422850251197815,\n",
       "  0.2546054720878601,\n",
       "  0.25500690937042236,\n",
       "  0.2553832530975342,\n",
       "  0.25561681389808655,\n",
       "  0.2560926675796509,\n",
       "  0.2564971446990967,\n",
       "  0.25690221786499023,\n",
       "  0.2571968734264374,\n",
       "  0.2575890123844147,\n",
       "  0.25777390599250793,\n",
       "  0.2583070397377014,\n",
       "  0.25872284173965454,\n",
       "  0.258833646774292,\n",
       "  0.25927209854125977,\n",
       "  0.2595949172973633,\n",
       "  0.25987300276756287,\n",
       "  0.2602066397666931,\n",
       "  0.26061177253723145,\n",
       "  0.2611064612865448,\n",
       "  0.26148560643196106,\n",
       "  0.26184460520744324,\n",
       "  0.26253947615623474,\n",
       "  0.26294609904289246,\n",
       "  0.2632827162742615,\n",
       "  0.26350995898246765,\n",
       "  0.2636459767818451,\n",
       "  0.2637813985347748,\n",
       "  0.26421013474464417,\n",
       "  0.26469823718070984,\n",
       "  0.264924556016922,\n",
       "  0.2653813660144806,\n",
       "  0.26550960540771484,\n",
       "  0.26601311564445496,\n",
       "  0.26618820428848267,\n",
       "  0.2665175199508667,\n",
       "  0.2670389711856842,\n",
       "  0.2673409581184387,\n",
       "  0.2675304412841797,\n",
       "  0.26772943139076233,\n",
       "  0.2682400643825531,\n",
       "  0.2688828110694885,\n",
       "  0.26943445205688477,\n",
       "  0.26953452825546265,\n",
       "  0.26978373527526855,\n",
       "  0.2700333595275879,\n",
       "  0.2703515589237213,\n",
       "  0.2707602381706238,\n",
       "  0.27080556750297546,\n",
       "  0.27144432067871094,\n",
       "  0.27164459228515625,\n",
       "  0.27187472581863403,\n",
       "  0.2724979817867279,\n",
       "  0.27257975935935974,\n",
       "  0.2729650139808655,\n",
       "  0.2732364237308502,\n",
       "  0.27338308095932007,\n",
       "  0.27369722723960876,\n",
       "  0.27405232191085815,\n",
       "  0.2744255065917969,\n",
       "  0.27470850944519043,\n",
       "  0.2750171720981598,\n",
       "  0.2754572331905365,\n",
       "  0.2757112681865692,\n",
       "  0.2760474681854248,\n",
       "  0.2765246331691742,\n",
       "  0.2769312262535095,\n",
       "  0.2770939767360687,\n",
       "  0.27733278274536133,\n",
       "  0.27764657139778137,\n",
       "  0.2778477370738983,\n",
       "  0.27818673849105835,\n",
       "  0.27867379784584045,\n",
       "  0.2788359522819519,\n",
       "  0.2795015871524811,\n",
       "  0.2798175513744354,\n",
       "  0.2799214720726013,\n",
       "  0.28039857745170593,\n",
       "  0.2806164622306824,\n",
       "  0.2808804512023926,\n",
       "  0.28086864948272705,\n",
       "  0.28146350383758545,\n",
       "  0.28167223930358887,\n",
       "  0.28190264105796814,\n",
       "  0.28226518630981445,\n",
       "  0.2826521694660187,\n",
       "  0.2831549048423767,\n",
       "  0.2836008667945862,\n",
       "  0.2837914526462555,\n",
       "  0.2841612696647644,\n",
       "  0.2843259274959564,\n",
       "  0.28477954864501953,\n",
       "  0.28497132658958435,\n",
       "  0.2852751314640045,\n",
       "  0.2854478061199188,\n",
       "  0.28568440675735474,\n",
       "  0.28591156005859375,\n",
       "  0.2865159213542938,\n",
       "  0.28681543469429016,\n",
       "  0.28716138005256653,\n",
       "  0.28724566102027893,\n",
       "  0.28787076473236084,\n",
       "  0.28802934288978577,\n",
       "  0.2882212996482849,\n",
       "  0.2885143756866455,\n",
       "  0.28900113701820374,\n",
       "  0.2891751229763031,\n",
       "  0.2894684076309204,\n",
       "  0.289585679769516,\n",
       "  0.29011690616607666,\n",
       "  0.2904307246208191,\n",
       "  0.290696382522583,\n",
       "  0.29128599166870117,\n",
       "  0.2912020683288574,\n",
       "  0.2914417088031769,\n",
       "  0.29171961545944214,\n",
       "  0.29227858781814575,\n",
       "  0.2925221920013428,\n",
       "  0.2927819490432739,\n",
       "  0.2929340898990631,\n",
       "  0.2933962047100067,\n",
       "  0.29379943013191223,\n",
       "  0.2941591143608093,\n",
       "  0.2944822609424591,\n",
       "  0.29476112127304077,\n",
       "  0.29490286111831665,\n",
       "  0.29508092999458313,\n",
       "  0.29542237520217896,\n",
       "  0.2954990267753601,\n",
       "  0.29586687684059143,\n",
       "  0.2962511479854584,\n",
       "  0.2964971363544464,\n",
       "  0.29684439301490784,\n",
       "  0.29708626866340637,\n",
       "  0.2972257733345032,\n",
       "  0.2975797653198242,\n",
       "  0.29810118675231934,\n",
       "  0.2983304262161255,\n",
       "  0.2985577881336212,\n",
       "  0.29864683747291565,\n",
       "  0.29855838418006897,\n",
       "  0.2992357909679413,\n",
       "  0.2995704114437103,\n",
       "  0.3001832067966461,\n",
       "  0.3006710112094879,\n",
       "  0.3006286323070526,\n",
       "  0.3009915351867676,\n",
       "  0.30103176832199097,\n",
       "  0.3016042113304138,\n",
       "  0.30201515555381775,\n",
       "  0.30210936069488525,\n",
       "  0.30247828364372253,\n",
       "  0.3026540279388428,\n",
       "  0.30327922105789185,\n",
       "  0.3035828471183777,\n",
       "  0.3037954270839691,\n",
       "  0.3039531111717224,\n",
       "  0.30452853441238403,\n",
       "  0.304540753364563,\n",
       "  0.3049277067184448,\n",
       "  0.3053918182849884,\n",
       "  0.30577796697616577,\n",
       "  0.3057951331138611,\n",
       "  0.3058777153491974,\n",
       "  0.30638232827186584,\n",
       "  0.3066793382167816,\n",
       "  0.3069019317626953,\n",
       "  0.307070255279541,\n",
       "  0.3072825074195862,\n",
       "  0.307616263628006,\n",
       "  0.30804282426834106,\n",
       "  0.30853667855262756,\n",
       "  0.3089086413383484,\n",
       "  0.3090285062789917,\n",
       "  0.30906975269317627,\n",
       "  0.30900028347969055,\n",
       "  0.30963051319122314,\n",
       "  0.31011882424354553,\n",
       "  0.3105686604976654,\n",
       "  0.3110434412956238,\n",
       "  0.31143850088119507,\n",
       "  0.31166067719459534,\n",
       "  0.31213951110839844,\n",
       "  0.3124849498271942,\n",
       "  0.31258609890937805,\n",
       "  0.3129214346408844,\n",
       "  0.3132440149784088,\n",
       "  0.3133622109889984,\n",
       "  0.31365737318992615,\n",
       "  0.313839852809906,\n",
       "  0.31411948800086975,\n",
       "  0.31446725130081177,\n",
       "  0.3147367537021637,\n",
       "  0.3149676024913788,\n",
       "  0.315279096364975,\n",
       "  0.31571879982948303,\n",
       "  0.31585922837257385,\n",
       "  0.3161795139312744,\n",
       "  0.3164220452308655,\n",
       "  0.3166773021221161,\n",
       "  0.31683844327926636,\n",
       "  0.31717872619628906,\n",
       "  0.3172561824321747,\n",
       "  0.31762415170669556,\n",
       "  0.3180038332939148,\n",
       "  0.31836387515068054,\n",
       "  0.31852248311042786,\n",
       "  0.31890127062797546,\n",
       "  0.31934529542922974,\n",
       "  0.31984084844589233,\n",
       "  0.32004180550575256,\n",
       "  0.32027193903923035,\n",
       "  0.3207184970378876,\n",
       "  0.32106566429138184,\n",
       "  0.3214589059352875,\n",
       "  0.3218989372253418,\n",
       "  0.3219078481197357,\n",
       "  0.3222218155860901,\n",
       "  0.3224114775657654,\n",
       "  0.3226882219314575,\n",
       "  0.32293468713760376,\n",
       "  0.32324638962745667,\n",
       "  0.3234517574310303,\n",
       "  0.32353419065475464,\n",
       "  0.3238760530948639,\n",
       "  0.3241344392299652,\n",
       "  0.32434576749801636,\n",
       "  0.32472649216651917,\n",
       "  0.32507818937301636,\n",
       "  0.3252409100532532,\n",
       "  0.3254378139972687,\n",
       "  0.32571497559547424,\n",
       "  0.3258034586906433,\n",
       "  0.32607558369636536,\n",
       "  0.3263373076915741,\n",
       "  0.3267488479614258,\n",
       "  0.3270522952079773,\n",
       "  0.32738998532295227,\n",
       "  0.3275533616542816,\n",
       "  0.32787805795669556,\n",
       "  0.32820719480514526,\n",
       "  0.328644722700119,\n",
       "  0.32876577973365784,\n",
       "  0.32885777950286865,\n",
       "  0.329127699136734,\n",
       "  0.3294232487678528,\n",
       "  0.3297780454158783,\n",
       "  0.3299875855445862,\n",
       "  0.3301403522491455,\n",
       "  0.3302689790725708,\n",
       "  0.330702543258667,\n",
       "  0.33085015416145325,\n",
       "  0.331190824508667,\n",
       "  0.3315517008304596,\n",
       "  0.33175379037857056,\n",
       "  0.3319797217845917,\n",
       "  0.33242180943489075,\n",
       "  0.33272892236709595,\n",
       "  0.3330996036529541,\n",
       "  0.33341681957244873,\n",
       "  0.3336018919944763,\n",
       "  0.33401021361351013,\n",
       "  0.33461859822273254,\n",
       "  0.33488017320632935,\n",
       "  0.3351435661315918,\n",
       "  0.33551496267318726,\n",
       "  0.3358403146266937,\n",
       "  0.33615997433662415,\n",
       "  0.3364832401275635,\n",
       "  0.33659827709198,\n",
       "  0.33678048849105835,\n",
       "  0.3371301293373108,\n",
       "  0.337245374917984,\n",
       "  0.33746588230133057]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1669204764474,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "Ehjy6IBSq6e5",
    "outputId": "3c70e3ea-3a1e-4e68-8856-ad0ead8c4cd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669204764475,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "T_FkDgmerg-X"
   },
   "outputs": [],
   "source": [
    "#1.initilize the ANN model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#2.Pass hidden layer\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "\n",
    "#3.Pass Activation function\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "#4.to establish the connection between layers\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669204764476,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "cUHmCXinsoOC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669204764477,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "lrwoJTTetK0j"
   },
   "outputs": [],
   "source": [
    "earlystop=EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3632,
     "status": "ok",
     "timestamp": 1669204768097,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "n3xAlhgsv-fA",
    "outputId": "ee74e1fa-8fea-43e2-930c-b6a0e9cb96a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.9436 - val_loss: 0.7135\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5962 - val_loss: 0.5016\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4186 - val_loss: 0.3886\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3228 - val_loss: 0.3232\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2641 - val_loss: 0.2787\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2240 - val_loss: 0.2454\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.2194\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1708 - val_loss: 0.1982\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1520 - val_loss: 0.1813\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1366 - val_loss: 0.1674\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1235 - val_loss: 0.1567\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1133 - val_loss: 0.1473\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1046 - val_loss: 0.1402\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0969 - val_loss: 0.1340\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0909 - val_loss: 0.1286\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0852 - val_loss: 0.1245\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0806 - val_loss: 0.1215\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0754 - val_loss: 0.1187\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0718 - val_loss: 0.1161\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0684 - val_loss: 0.1140\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.1122\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.1107\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0602 - val_loss: 0.1087\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0579 - val_loss: 0.1080\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0560 - val_loss: 0.1076\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0538 - val_loss: 0.1072\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0522 - val_loss: 0.1063\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0505 - val_loss: 0.1055\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0492 - val_loss: 0.1044\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0476 - val_loss: 0.1037\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0464 - val_loss: 0.1032\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0452 - val_loss: 0.1035\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.1032\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0428 - val_loss: 0.1019\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0418 - val_loss: 0.1016\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0406 - val_loss: 0.1021\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.1028\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0387 - val_loss: 0.1030\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0378 - val_loss: 0.1029\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0370 - val_loss: 0.1025\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0361 - val_loss: 0.1027\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0352 - val_loss: 0.1025\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0343 - val_loss: 0.1026\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0335 - val_loss: 0.1022\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0331 - val_loss: 0.1053\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0317 - val_loss: 0.1052\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0309 - val_loss: 0.1047\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.1047\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.1054\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.1025\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.1032\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.1062\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.1070\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.1086\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.1098\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0244 - val_loss: 0.1098\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.1101\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.1112\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.1136\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.1126\n",
      "Epoch 60: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2c52fcd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest),callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1669204768956,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "FnqveQRgwkse",
    "outputId": "7def24c9-254e-4ac8-9095-bb430f95caf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669204768957,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "PXgw11YfyhW5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1669204768958,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "lHUfUtbIx9Rg"
   },
   "outputs": [],
   "source": [
    "#1.initilize the ANN model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#2.Pass hidden layer\n",
    "\n",
    "model.add(Dense(units=30,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#3.Pass Activation function\n",
    "\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "#4.to establish the connection between layers\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8164,
     "status": "ok",
     "timestamp": 1669204777114,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "HBBB5TxHzEpG",
    "outputId": "d7b4acae-6631-42e4-95c6-b5fe0fc34319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 0.7059 - val_loss: 0.4778\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5814 - val_loss: 0.4012\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5489 - val_loss: 0.3503\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4449 - val_loss: 0.3113\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4740 - val_loss: 0.2795\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3895 - val_loss: 0.2521\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3393 - val_loss: 0.2319\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3034 - val_loss: 0.2152\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.2010\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2833 - val_loss: 0.1873\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2661 - val_loss: 0.1774\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2372 - val_loss: 0.1682\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2250 - val_loss: 0.1604\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2196 - val_loss: 0.1521\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1815 - val_loss: 0.1466\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1844 - val_loss: 0.1423\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1796 - val_loss: 0.1382\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1514 - val_loss: 0.1339\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1725 - val_loss: 0.1305\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1401 - val_loss: 0.1270\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1483 - val_loss: 0.1246\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1579 - val_loss: 0.1224\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1589 - val_loss: 0.1201\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1288 - val_loss: 0.1182\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1160 - val_loss: 0.1173\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1371 - val_loss: 0.1164\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1077 - val_loss: 0.1149\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1333 - val_loss: 0.1148\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1170 - val_loss: 0.1153\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0987 - val_loss: 0.1164\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1054 - val_loss: 0.1153\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1076 - val_loss: 0.1150\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1083 - val_loss: 0.1144\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0852 - val_loss: 0.1148\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1147 - val_loss: 0.1146\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1349 - val_loss: 0.1145\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0892 - val_loss: 0.1153\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0912 - val_loss: 0.1172\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0822 - val_loss: 0.1176\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0831 - val_loss: 0.1184\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0845 - val_loss: 0.1182\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1022 - val_loss: 0.1181\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0860 - val_loss: 0.1187\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0831 - val_loss: 0.1195\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.1198\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0827 - val_loss: 0.1215\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0962 - val_loss: 0.1218\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0807 - val_loss: 0.1217\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0769 - val_loss: 0.1202\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0966 - val_loss: 0.1206\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0872 - val_loss: 0.1211\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0729 - val_loss: 0.1214\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0712 - val_loss: 0.1207\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0572 - val_loss: 0.1207\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.1207\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0822 - val_loss: 0.1214\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0657 - val_loss: 0.1211\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0714 - val_loss: 0.1210\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc29ccab50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=600,validation_data=(xtest,ytest),callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1669204778082,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "CDYSkH86wliW",
    "outputId": "46d2d755-7fa7-4086-cbad-e826c63b92dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(model.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1669204778083,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "lhraaHHSzVRP",
    "outputId": "6c484b9c-bb18-493f-c5e2-80526e31c732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669204778084,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "7IgD1DU11694"
   },
   "outputs": [],
   "source": [
    "ypred=ypred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669204778085,
     "user": {
      "displayName": "Naveen PL",
      "userId": "15731215887950391536"
     },
     "user_tz": -330
    },
    "id": "MqlYiApV19k6",
    "outputId": "74f4a5d7-85fa-4c06-dd3f-abf0231a690a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        63\n",
      "           1       0.97      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOP0j8IPzvaNmOczdnFPtKL",
   "mount_file_id": "1QXkuyUM71Tup9NpRxLAIBfSrqbCulx5M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
